{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaeb3ba-3868-466a-b735-8f360ba7f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "#!ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2:1b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has a wide range of business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can be used to create high-quality, engaging content such as articles, social media posts, product descriptions, and even entire websites. Companies like Google, Amazon, and Microsoft have already started using generative models for content generation.\n",
      "2. **Automated Customer Service**: Generative AI can help automate customer service by generating responses to common customer inquiries, freeing up human agents to focus on more complex issues. This can lead to improved customer satisfaction and reduced operational costs.\n",
      "3. **Personalized Marketing**: Generative AI can be used to create personalized marketing messages, offers, and content based on customers' browsing history, purchase behavior, and preferences. This can help increase conversion rates and improve customer loyalty.\n",
      "4. **Design Automation**: Generative AI can generate design concepts, products, or even entire products based on specifications provided by humans. This can save time and resources for companies in industries like manufacturing, architecture, and product design.\n",
      "5. **Virtual Product Demos**: Generative AI can create immersive virtual product demos that allow customers to try out products or services virtually before making a purchase. This can help improve sales conversion rates and reduce the risk of returns.\n",
      "6. **Predictive Maintenance**: Generative AI can analyze sensor data from machines and predict when maintenance is required, reducing downtime and improving overall efficiency.\n",
      "7. **Quality Control**: Generative AI can be used to generate test cases, scripts, or even entire testing frameworks for software applications, reducing manual effort and improving code quality.\n",
      "8. **Cybersecurity Threat Detection**: Generative AI can analyze patterns in network traffic and identify potential security threats before they become actual attacks, helping companies to protect their networks and data.\n",
      "9. **Medical Imaging Analysis**: Generative AI can help medical professionals analyze medical images such as MRI or CT scans, identifying abnormalities and making diagnoses more accurately.\n",
      "10. **Supply Chain Optimization**: Generative AI can optimize supply chain operations by predicting demand, identifying bottlenecks, and suggesting alternative routes for logistics and transportation.\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As this technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has a wide range of business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can be used to create high-quality content, such as articles, social media posts, and product descriptions, reducing the need for human writers and increasing efficiency.\n",
      "2. **Design and Visualization**: Generative AI can generate visualizations, 3D models, and designs for products, marketing campaigns, and other creative projects, enhancing innovation and productivity.\n",
      "3. **Customer Experience**: Generative AI can be used to create personalized customer experiences through chatbots, virtual assistants, and automated customer service systems.\n",
      "4. **Marketing Automation**: Generative AI can help automate repetitive tasks in marketing, such as lead generation, email campaigns, and social media engagement, freeing up human marketers to focus on strategy and creativity.\n",
      "5. **Predictive Maintenance**: Generative AI can analyze sensor data from machines and predict when maintenance is required, reducing downtime and increasing overall efficiency.\n",
      "6. **Supply Chain Optimization**: Generative AI can help optimize supply chain operations by predicting demand, routing logistics, and identifying potential bottlenecks.\n",
      "7. **Healthcare Research**: Generative AI can assist in the analysis of medical data, generating insights on disease patterns, treatment outcomes, and personalized medicine recommendations.\n",
      "8. **Financial Modeling**: Generative AI can help create complex financial models, automating tasks such as risk assessment, scenario planning, and forecasting.\n",
      "9. **Identity Verification**: Generative AI-powered identity verification systems can quickly and accurately verify identities in real-time applications, reducing the risk of identity theft and fraud.\n",
      "10. **Business Intelligence**: Generative AI can be used to generate reports, dashboards, and other business intelligence tools, providing insights on company performance, market trends, and competitor activity.\n",
      "\n",
      "In specific industries:\n",
      "\n",
      "1. **Finance**: Generative AI can help with tasks such as loan assessment, credit scoring, and portfolio optimization.\n",
      "2. **Retail**: Generative AI-powered chatbots can assist customers with product recommendations, returns, and other queries.\n",
      "3. **Manufacturing**: Generative AI can optimize production processes by predicting equipment failures, optimizing batch sizes, and scheduling maintenance.\n",
      "4. **Travel**: Generative AI can help plan personalized itineraries, suggest travel routes, and provide customized destination recommendations.\n",
      "5. **Education**: Generative AI-powered adaptive learning platforms can tailor the learning experience to individual students' needs, abilities, and goals.\n",
      "\n",
      "These are just a few examples of the business applications of generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bf436b3-9dcd-488c-9cd1-5241b060bf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest √¢¬†‚Äπ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest √¢¬†‚Ñ¢ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest √¢¬†¬π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest √¢¬†¬∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest √¢¬†¬º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest √¢¬†¬¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest √¢¬†¬¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest √¢¬†¬ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest √¢¬†‚Ä° \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest √¢¬†ÔøΩ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest √¢¬†‚Äπ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest √¢¬†‚Ñ¢ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest √¢¬†¬π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest √¢¬†¬∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest √¢¬†¬º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8: 100% √¢‚Äì‚Ä¢√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÔøΩ 1.1 GB                         \u001b[K\n",
      "pulling c5ad996bda6e: 100% √¢‚Äì‚Ä¢√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÔøΩ  556 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% √¢‚Äì‚Ä¢√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÔøΩ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% √¢‚Äì‚Ä¢√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÔøΩ  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% √¢‚Äì‚Ä¢√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÀÜ√¢‚ÄìÔøΩ  487 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to understand what underpins language models (LLMs), specifically focusing on neural networks, attention mechanisms, and transformers. I remember that LLMs are big AI systems that can generate or perform tasks like text generation, but I'm not entirely sure how they work behind the scenes. Let me start by thinking about each concept one by one.\n",
      "\n",
      "First, let's tackle neural networks since it's a broad area. I know that most AI models, including LLMs, rely heavily on neural networks. They're often referred to as deep learning models because they have multiple layers. So, what exactly is a neural network? It sounds like a series of layers that process information through interconnected nodes or neurons. Each layer processes data and then sends the processed information (like an activation vector) to the next layer. This way, each layer can extract new features from the data it receives.\n",
      "\n",
      "But how do these neural networks work together at different levels in LLMs? I think LLMs have a structured network with layers that handle specific tasks or parts of the generation process. Maybe the lower layers are focused on character-level processing (like individual words), and higher layers deal with longer-term dependencies, which could involve phrases or sentences as inputs.\n",
      "\n",
      "Now, looking at attention mechanisms. I remember hearing about this in the context of how LLMs focus more on what's important when making a prediction. Instead of considering every word in the text, the model can attend only to specific words that are relevant for generating certain outputs, like names or directions. This selective focus leads to shorter computation times and better performance.\n",
      "\n",
      "How does this attention work with the transformer architecture? Transformers have been revolutionary in AI, especially NLP tasks because they are based on different computational models compared to recurrent neural networks (RNNs). The key difference is that in transformers, each layer processes data in both directions. That means information propagates in two opposite ways through the layers, allowing for parallel processing and addressing some limitations of RNNs with sequential data.\n",
      "\n",
      "So, putting this together, LLMs use a neural network structure composed of multiple layers operating at different levels. The attention mechanism allows the model to focus on relevant parts of the input when its output is generated. Transformers enhance this by handling data in both directions through their block structures and utilizing attention within these blocks. Together, each component contributes to the model's ability to process complex tasks through layers that extract features from inputs and generate outputs with improved effectiveness.\n",
      "</think>\n",
      "\n",
      "LLMs, such as language models, are built on several key components: neural networks, attention mechanisms, and transformers.\n",
      "\n",
      "1. **Neural Networks (Deep Learning Models):**\n",
      "   - Neural networks consist of interconnected nodes or neurons that process and transmit information through layers of data. Each layer extracts new features from the input by propagating an activation vector to the next layer.\n",
      "   - In LLMs, these networks are structured across multiple levels for character-level processing and handling longer-term dependencies. Lower layers focus on individual words, while higher layers consider larger chunks like sentences.\n",
      "\n",
      "2. **Attention Mechanisms:**\n",
      "   - Attention helps the model prioritize relevant information in input data when generating outputs, reducing reliance on all words without compromising performance.\n",
      "   - Unlike RNNs, which process data sequentially, attention allows the model focused on specific parts (e.g., names or directions), enhancing generation efficiency.\n",
      "\n",
      "3. **Transformers:**\n",
      "   - Built using block structures that process data in both directions simultaneously, transformers address memory issues seen with RNNs and better parallelize information for faster execution.\n",
      "   - Each transformer layer includes processing within blocks for character-level and longer-term contexts (phrases/phrases), focusing on relevant parts.\n",
      "\n",
      "**Conclusion:** \n",
      "LLMs leverage neural networks across levels,attention mechanisms for selective focus, and transformers for efficient sequential and parallel processing. Together, these components enable effective handling of complex data through layers that enhance feature extraction and output generation.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "# here used other model deepseek-r1:1.5b\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eaf902-13e7-4d63-983c-372c875d1218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1806432f-8087-4947-b865-cf5d3d68d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_model=\"deepseek-r1:1.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5806b4a-ce65-4b67-9d43-4aade0b80833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CloudXcellence - Control your cloud\n",
      "We helped AFC Ajax Amsterdam save 64% on their runtime hours.\n",
      "Read customer story\n",
      "Features\n",
      "Features\n",
      "Grip on costs\n",
      "Grip on access\n",
      "Grip on speed\n",
      "Grip on workloads\n",
      "Pricing\n",
      "Pricing\n",
      "Features\n",
      "Features\n",
      "Contact\n",
      "Contact\n",
      "Book a demo\n",
      "Book a demo\n",
      "Own your\n",
      "Azure cloud,\n",
      "Xcel your business.\n",
      "Reduce your cloud emissions. Improve your cloud performance. Lower your cloud costs. Be alerted if something is wrong. Up and running within hours.\n",
      "Making your Azure GreenOps actionable üöÄ\n",
      "Try it for free\n",
      "Try it for free\n",
      "30 day trial\n",
      "Cloud emissions insights\n",
      "RUNTIME¬†HOURS\n",
      "198\n",
      "56%\n",
      "From 455 hours last month\n",
      "ERRORS\n",
      "72\n",
      "92%\n",
      "From 907 errors last month\n",
      "AZURE¬†COSTS\n",
      "‚Ç¨ 2.323\n",
      "23%\n",
      "From ‚Ç¨2.858 last month\n",
      "64%\n",
      "saved on runtime hours\n",
      "‚ÄúCloudXcellence helped us create a complete overview of all datasources. This was needed to make a smooth switch to another provider of ticketing services. Otherwise we had to review hundreds of LogicApps manually which would have cost us a fortune!\"\n",
      "Read customer story\n",
      "Hey consultant or MSP, how can we support\n",
      "your\n",
      "cloud experts?\n",
      "As a service provider you want to deliver the best value to your clients but time of your experts is limited. We are here to help.\n",
      "So your cloud experts get valuable insights, save time investigating and start executing optimizations right away!\n",
      "Explore a partnership\n",
      "Schedule your Azure checkup\n",
      "Join our CXchange partner program.\n",
      "CloudXcellence supports companies in\n",
      "regaining grip\n",
      "on ‚Äãtheir Azure cloud\n",
      "Grip on costs üí∞\n",
      "Get an overview of all that‚Äôs up and running and stop paying for unnessary operations. #FinOps\n",
      "Grip on access üöÄ\n",
      "Efficiency meets security when CloudXcellence boosts your cloud access. #Security\n",
      "Grip on sustainability üå±\n",
      "Get insights on your Azure footprint and reduce emissions with our recommendations. #GreenOps\n",
      "Grip on performance üèéÔ∏è\n",
      "Eliminate waste by right sizing and rebalancing. Only pay for value, not for use. #FinOps\n",
      "How do you get CloudXcellence?\n",
      "1 ‚Äî See the product\n",
      "Book a free, no strings attached demo with one of our consultants and find out how you can control your Azure cloud.\n",
      "Book a demo\n",
      "2 ‚Äî Try it for free\n",
      "Our app is available on the Azure store. Enterprise graded and approved by Microsoft. No developer knowledge needed.\n",
      "Start free trial\n",
      "3 ‚Äî Join our partner program\n",
      "Our CXchange partner program boost your optimization services. We support the entire Azure optimisation journey of your clients!\n",
      "Explore a partnership\n",
      "258%\n",
      "saved on cloud costs\n",
      "‚ÄúWe reduced our Azure operational cost with $50k/mo after implementing CloudXcellence. CloudXcellence provided the necessary insights to start right sizing and rebalancing.\"\n",
      "Pricing\n",
      "Basic\n",
      "For independent operators\n",
      "Get Basic\n",
      "Get Basic\n",
      "‚Ç¨999\n",
      "/mo\n",
      "For independent operators\n",
      "Alerts from ADF or Logic Apps\n",
      "Mission critical events\n",
      "Cost optimization quick wins\n",
      "Basic support\n",
      "Pro\n",
      "Most popular\n",
      "More in-person support\n",
      "Get Pro\n",
      "Get Pro\n",
      "‚Ç¨1599\n",
      "/mo\n",
      "Realtime Usage Monitoring\n",
      "Alerts from ADF or Logic Apps\n",
      "Mission critical events\n",
      "Cost optimization quick wins\n",
      "Pro support\n",
      "Monthly Cloud Review\n",
      "Enterprise\n",
      "The complete package\n",
      "Talk to us\n",
      "Talk to us\n",
      "Call us\n",
      "For independent operators\n",
      "Alerts from ADF or Logic Apps\n",
      "Mission critical events\n",
      "Cost optimization quick wins\n",
      "Cloudops Coach at your service\n",
      "\"Sure, your cloud does work without CloudXcellence. But compare this with a car driving in first gear with a flat tire. Still it gets you from A to B. But it takes forever, produces extra emissions and is expensive.\"\n",
      "Henk van der Valk\n",
      "Founder CloudXcellence\n",
      "Cloud control with ease\n",
      "Azure GreenOps // Actionable\n",
      "Azure FinOps // Actionable\n",
      "Be alerted if something is wrong. Get a peace of mind about your Azure costs and performance. No developers required.\n",
      "Try it for free\n",
      "Try it for free\n",
      "Book a demo\n",
      "Book a demo\n",
      "30 day trial\n",
      "Cloud emission insights\n",
      "Start improving your cloud today:\n",
      "Try it for free\n",
      "CloudXcellence help companies control their cloud. Keeping tabs on costs, reduce emissions, improve performance\n",
      "#FinOps // #GreenOps // #Security\n",
      "Pricing\n",
      "Pricing\n",
      "Contact\n",
      "Contact\n",
      "Terms &¬†Conditions\n",
      "Terms &¬†Conditions\n",
      "Copyright ¬© 2025 CloudXcellence\n"
     ]
    }
   ],
   "source": [
    "# Let's try one out. Change the website and add print statements to follow along.\n",
    "\n",
    "ed = Website(\"https://cloudxcellence.com\")\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f576d-d324-4182-b73d-9d99f766125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc500399-611a-415b-ae91-3f35e5a1798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a52e5-91e1-4246-b59c-ac534324b1c3",
   "metadata": {},
   "source": [
    "print(user_prompt_for(ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80af029f-be73-4739-85b9-f271db130388",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a snarky assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28c25a78-db43-4660-b937-0ad5e7c9ce97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, so I've got this question here: \"What is 2 plus 2?\" At first glance, it seems pretty straightforward. I mean, addition is a basic math concept that everyone learns early on. But wait, the user mentioned something about being snarky. Hmm, maybe they're trying to keep things light or avoid using too much technical language. \n",
      "\n",
      "Okay, let's break this down. The question itself doesn't seem too complicated. You just add 2 and 2 together, which equals 4. That's simple enough. I wonder if the user was thinking about more advanced math problems or something that might require a deeper understanding. Perhaps they're testing my ability to handle different types of questions beyond basic arithmetic.\n",
      "\n",
      "But no, even at this level, I think the question is pretty direct. There are no tricks here, no substitutions, or anything like that. It's just an addition problem. Maybe the snarky part refers to something else, like being mischievous or trying to keep the conversation going. I'm not sure, but it seems a bit off.\n",
      "\n",
      "I guess the key point is that I should explain this clearly and accurately without any confusion. Since 2 plus 2 equals 4 is a fundamental fact, the user probably expected an easy answer, even if they threw in some unnecessary fluff about being snarky or using complex language. \n",
      "\n",
      "So, to sum it up, the question is just asking for a simple addition, and I can confidently say that it's equal to 4 without any doubt. There isn't anything tricky or hidden here, so no need to overcomplicate things with any jokes or elaborate explanations.\n",
      "</think>\n",
      "\n",
      "**2 + 2 equals 4.** This is a fundamental arithmetic operation where adding two units to another two units results in a total of four units. It is straightforward and does not require any complex calculations or substitutions.\n"
     ]
    }
   ],
   "source": [
    "# To give you a preview -- calling OpenAI with system and user messages:\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(model=\"deepseek-r1:1.5b\", messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44d81169-c52c-49a7-a00a-fbbb82c5543d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow, I'm just so excited to help with such a complex calculation. Let me put on my thinking cap and use my extensive knowledge of ancient Greek mathematics... *ahem*.\n",
      "\n",
      "Seriously though, the answer to 2 + 2 is obviously 4. Now, if you'll excuse me, I have better things to do than hold your hand through basic arithmetic all day. Next thing you know, you'll be asking me how to breathe or something...\n"
     ]
    }
   ],
   "source": [
    "response = ollama_via_openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c8b84d0-457f-4d94-b2ce-6e8ea862bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc79527e-8b10-464e-8bb5-caccc450a6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an assistant that analyzes the contents of a website and provides a short summary, ignoring text that might be navigation related. Respond in markdown.'},\n",
       " {'role': 'user',\n",
       "  'content': 'You are looking at a website titled CloudXcellence - Control your cloud\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\nWe helped AFC Ajax Amsterdam save 64% on their runtime hours.\\nRead customer story\\nFeatures\\nFeatures\\nGrip on costs\\nGrip on access\\nGrip on speed\\nGrip on workloads\\nPricing\\nPricing\\nFeatures\\nFeatures\\nContact\\nContact\\nBook a demo\\nBook a demo\\nOwn your\\nAzure cloud,\\nXcel your business.\\nReduce your cloud emissions. Improve your cloud performance. Lower your cloud costs. Be alerted if something is wrong. Up and running within hours.\\nMaking your Azure GreenOps actionable üöÄ\\nTry it for free\\nTry it for free\\n30 day trial\\nCloud emissions insights\\nRUNTIME\\xa0HOURS\\n198\\n56%\\nFrom 455 hours last month\\nERRORS\\n72\\n92%\\nFrom 907 errors last month\\nAZURE\\xa0COSTS\\n‚Ç¨ 2.323\\n23%\\nFrom ‚Ç¨2.858 last month\\n64%\\nsaved on runtime hours\\n‚ÄúCloudXcellence helped us create a complete overview of all datasources. This was needed to make a smooth switch to another provider of ticketing services. Otherwise we had to review hundreds of LogicApps manually which would have cost us a fortune!\"\\nRead customer story\\nHey consultant or MSP, how can we support\\nyour\\ncloud experts?\\nAs a service provider you want to deliver the best value to your clients but time of your experts is limited. We are here to help.\\nSo your cloud experts get valuable insights, save time investigating and start executing optimizations right away!\\nExplore a partnership\\nSchedule your Azure checkup\\nJoin our CXchange partner program.\\nCloudXcellence supports companies in\\nregaining grip\\non \\u200btheir Azure cloud\\nGrip on costs üí∞\\nGet an overview of all that‚Äôs up and running and stop paying for unnessary operations. #FinOps\\nGrip on access üöÄ\\nEfficiency meets security when CloudXcellence boosts your cloud access. #Security\\nGrip on sustainability üå±\\nGet insights on your Azure footprint and reduce emissions with our recommendations. #GreenOps\\nGrip on performance üèéÔ∏è\\nEliminate waste by right sizing and rebalancing. Only pay for value, not for use. #FinOps\\nHow do you get CloudXcellence?\\n1 ‚Äî See the product\\nBook a free, no strings attached demo with one of our consultants and find out how you can control your Azure cloud.\\nBook a demo\\n2 ‚Äî Try it for free\\nOur app is available on the Azure store. Enterprise graded and approved by Microsoft. No developer knowledge needed.\\nStart free trial\\n3 ‚Äî Join our partner program\\nOur CXchange partner program boost your optimization services. We support the entire Azure optimisation journey of your clients!\\nExplore a partnership\\n258%\\nsaved on cloud costs\\n‚ÄúWe reduced our Azure operational cost with $50k/mo after implementing CloudXcellence. CloudXcellence provided the necessary insights to start right sizing and rebalancing.\"\\nPricing\\nBasic\\nFor independent operators\\nGet Basic\\nGet Basic\\n‚Ç¨999\\n/mo\\nFor independent operators\\nAlerts from ADF or Logic Apps\\nMission critical events\\nCost optimization quick wins\\nBasic support\\nPro\\nMost popular\\nMore in-person support\\nGet Pro\\nGet Pro\\n‚Ç¨1599\\n/mo\\nRealtime Usage Monitoring\\nAlerts from ADF or Logic Apps\\nMission critical events\\nCost optimization quick wins\\nPro support\\nMonthly Cloud Review\\nEnterprise\\nThe complete package\\nTalk to us\\nTalk to us\\nCall us\\nFor independent operators\\nAlerts from ADF or Logic Apps\\nMission critical events\\nCost optimization quick wins\\nCloudops Coach at your service\\n\"Sure, your cloud does work without CloudXcellence. But compare this with a car driving in first gear with a flat tire. Still it gets you from A to B. But it takes forever, produces extra emissions and is expensive.\"\\nHenk van der Valk\\nFounder CloudXcellence\\nCloud control with ease\\nAzure GreenOps // Actionable\\nAzure FinOps // Actionable\\nBe alerted if something is wrong. Get a peace of mind about your Azure costs and performance. No developers required.\\nTry it for free\\nTry it for free\\nBook a demo\\nBook a demo\\n30 day trial\\nCloud emission insights\\nStart improving your cloud today:\\nTry it for free\\nCloudXcellence help companies control their cloud. Keeping tabs on costs, reduce emissions, improve performance\\n#FinOps // #GreenOps // #Security\\nPricing\\nPricing\\nContact\\nContact\\nTerms &\\xa0Conditions\\nTerms &\\xa0Conditions\\nCopyright ¬© 2025 CloudXcellence'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this out, and then try for a few more websites\n",
    "\n",
    "messages_for(ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f4d4c96-a8e0-4c7d-9c5e-cc29d8e22b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "        model = MODEL,\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfc64b6c-5740-4198-b643-accb6ab556c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Introduction to CloudXcellence\\n\\nCloudXcellence is a service that helps companies control and optimize their Azure cloud infrastructure. It provides features such as cost reduction, improved performance, and enhanced security.\\n\\n#### Key Features\\n\\n* Cost optimization: reduces cloud costs by 64%\\n* Performance improvement: eliminates waste by right-sizing and rebalancing workloads\\n* Security improvements: boosts cloud access with real-time usage monitoring\\n* Sustainability insights: tracks Azure footprint and reduces emissions\\n\\n#### Customer Story\\n\\nAFC Ajax Amsterdam, a professional club in the Netherlands, used CloudXcellence to save 64% on their runtime hours. They were facing complex operational issues due to inefficient cloud management.\\n\\n#### News/A announcements\\n\\n* CloudXcellence announced a 30-day trial period for its customers allowing them to try out the service without any commitment\\n* The company also mentioned that it has supported companies in regaining grip on their Azure cloud, providing valuable insights into cost optimization, security, sustainability, and performance'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://cloudxcellence.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a703ab1-055b-4f6f-b290-592a1b9d05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f346b56e-0249-418b-b511-b010e1ca1229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**CloudXcellence Overview**\n",
       "Markdown summary:\n",
       "CloudXcellence is a service that helps companies optimize and control their Azure cloud resources, improving efficiency, security, sustainability, and performance. It provides access to insights and features that enable companies to regain grip on their Azure cloud, reduce costs and emissions, and improve overall effectiveness.\n",
       "\n",
       "**Key Features and Benefits**\n",
       "Markdown summary:\n",
       "- **Grip on Costs**: Offers cost optimization quick wins, proactive error resolution, and real-time usage monitoring.\n",
       "- **Grip on Access**: Enhances security by boosting cloud access, making it efficient for operations.\n",
       "- **Grip on Sustainability**: Measures Azure footprint and provides recommendations to reduce emissions.\n",
       "- **Grip on Performance**: Identifies areas for right sizing and rebalancing to optimize cost-effectiveness.\n",
       "\n",
       "**Notable News or Announcements**\n",
       "Markdown summary:\n",
       "- CloudXcellence helped AFC Ajax Amsterdam save 64% on their runtime hours by implementing optimized cloud costs.\n",
       "- Implemented a complete overview of all datasources, making a smooth switch to another provider easier without manual error review.\n",
       "- Introduced a 30-day trial for free access to the service.\n",
       "\n",
       "**Why Choose CloudXcellence**\n",
       "Markdown summary:\n",
       "- Supports independent operators with flexibility in pricing plans (Basic to Enterprise), including alerts from ADF or Logic Apps.\n",
       "- Offers real-time usage monitoring, helping companies optimize usage and reduce costs.\n",
       "- Implements proactive error resolution for a smooth optimization journey."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://cloudxcellence.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b62a8d7a-1d0b-4aef-931b-aea7a1621cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! It's great to meet you. I'm excited to help and chat with you. Is there something specific you'd like to talk about or ask me? I'm all ears (or rather, all text).\n"
     ]
    }
   ],
   "source": [
    "# To give you a preview -- calling OpenAI with these messages is this easy. Any problems, head over to the Troubleshooting notebook.\n",
    "\n",
    "message = \"Hello, GPT! This is my first ever message to you! Hi!\"\n",
    "response = ollama_via_openai.chat.completions.create(model=MODEL, messages=[{\"role\":\"user\", \"content\":message}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d27ed37-bb04-4bdd-bed7-4f3cc7948a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The article is an update of CNN's coverage, focusing on several major news stories from June 16, 2025. Here are the key points:\n",
       "\n",
       "1. **Middle East Conflict**: The Israeli-Palestinian conflict remains a point of tension, with airstrikes and skirmishes reported around the Gaza Strip.\n",
       "2. **Arrests in France**: Four people have been arrested in connection to the murder of Vincent Vinciguia's girlfriend on social media.\n",
       "3. **New Report from 688-Year-Old Murder Case**: A new investigation into the medieval case reveals a tangled web of adultery and extortion, shedding light on the lives of those involved at that time.\n",
       "4. **Beirut Blast Investigation**: Research has been conducted to restore damaged artworks after a Beirut blast, highlighting efforts to preserve history and cultural heritage.\n",
       "\n",
       "These stories are being covered in a special report for viewers around the world, offering insights into pressing global issues and local developments from June 16, 2025."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7aaabf4-9479-4430-a7d2-6defaa1b34cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Invia Group Overview\n",
       "\n",
       "*   The website provides an overview of the company, emphasizing its focus on providing holiday expert services across Europe and promoting a large network.\n",
       "    *   **Company Structure**: Invia is described as \"THE\" provider for holidays in the industry. It also mentions starting a growing business.\n",
       "\n",
       "### Careers at Invia\n",
       "\n",
       "*   The section focuses on exploring available careers within the company, highlighting growth opportunities.\n",
       "    *   **Job Description**: There's no explicit job description provided, but it can be inferred that career openings might involve working closely with customers and other teams to contribute to the company's mission.\n",
       "\n",
       "### Upcoming Year: Invia Group 2025\n",
       "\n",
       "*   This section is likely related to the company's plan for the upcoming year.\n",
       "    *   **Key Highlights**: As no specific details are mentioned, some assumptions have been made:\n",
       "\n",
       "        :   The \"Invia Group 2025\" refers to an outline of the company's ambitions for future growth and development.\n",
       "            :   These might include expanding its customer base, enhancing services, or exploring international collaborations.\n",
       "\n",
       "   "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://www.invia.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2bf4a2-b60a-4ebf-8bdd-357582c58f43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
